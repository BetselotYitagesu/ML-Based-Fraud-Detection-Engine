{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57fb61cd",
   "metadata": {},
   "source": [
    "## 2.1 Data Preparation\n",
    "\n",
    "Before model training, I need first isolate our features and target labels from both datasets.  \n",
    "I  also split the data into training and test sets using stratification to maintain class balance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810c7a8c",
   "metadata": {},
   "source": [
    "#### üîÑ Step 1: Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cd031eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load FRAUD DATA\n",
    "X_train_fraud = pd.read_csv('../data/processed/X_train_final.csv')\n",
    "y_train_fraud = pd.read_csv('../data/processed/y_train_final.csv').squeeze()\n",
    "X_test_fraud = pd.read_csv('../data/processed/X_test_final.csv')\n",
    "y_test_fraud = pd.read_csv('../data/processed/y_test_final.csv').squeeze()\n",
    "\n",
    "# Load CREDIT CARD DATA\n",
    "X_train_credit = pd.read_csv('../data/processed/X_train_final_credit.csv')\n",
    "y_train_credit = pd.read_csv('../data/processed/y_train_final_credit.csv').squeeze()\n",
    "X_test_credit = pd.read_csv('../data/processed/X_test_final_credit.csv')\n",
    "y_test_credit = pd.read_csv('../data/processed/y_test_final_credit.csv').squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951ab83f",
   "metadata": {},
   "source": [
    "#### ü§ñ Step 2: Train and Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de6e5904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve, auc, f1_score, confusion_matrix\n",
    "\n",
    "def evaluate_models(X_train, y_train, X_test, y_test, dataset_name=\"\"):\n",
    "    print(f\"\\nüìä Results for {dataset_name} Dataset\\n\" + \"-\"*40)\n",
    "    \n",
    "    # Define models\n",
    "    lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Train\n",
    "    lr.fit(X_train, y_train)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict probabilities\n",
    "    lr_probs = lr.predict_proba(X_test)[:, 1]\n",
    "    rf_probs = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Predict classes\n",
    "    lr_preds = lr.predict(X_test)\n",
    "    rf_preds = rf.predict(X_test)\n",
    "\n",
    "    # AUC-PR\n",
    "    def auc_pr(y_true, y_prob):\n",
    "        precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
    "        return auc(recall, precision)\n",
    "\n",
    "    lr_aucpr = auc_pr(y_test, lr_probs)\n",
    "    rf_aucpr = auc_pr(y_test, rf_probs)\n",
    "\n",
    "    # F1-scores\n",
    "    lr_f1 = f1_score(y_test, lr_preds)\n",
    "    rf_f1 = f1_score(y_test, rf_preds)\n",
    "\n",
    "    # Confusion Matrices\n",
    "    lr_cm = confusion_matrix(y_test, lr_preds)\n",
    "    rf_cm = confusion_matrix(y_test, rf_preds)\n",
    "\n",
    "    # Print results\n",
    "    print(\"üîπ Logistic Regression:\")\n",
    "    print(f\" - AUC-PR: {lr_aucpr:.4f}\")\n",
    "    print(f\" - F1 Score: {lr_f1:.4f}\")\n",
    "    print(f\" - Confusion Matrix:\\n{lr_cm}\\n\")\n",
    "\n",
    "    print(\"üî∏ Random Forest:\")\n",
    "    print(f\" - AUC-PR: {rf_aucpr:.4f}\")\n",
    "    print(f\" - F1 Score: {rf_f1:.4f}\")\n",
    "    print(f\" - Confusion Matrix:\\n{rf_cm}\")\n",
    "\n",
    "    #‚úÖ Return trained models\n",
    "    return lr, rf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcf0bad",
   "metadata": {},
   "source": [
    "#### üèÅ Step 3: Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21a5b4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Results for Fraud_Data Dataset\n",
      "----------------------------------------\n",
      "üîπ Logistic Regression:\n",
      " - AUC-PR: 0.2554\n",
      " - F1 Score: 0.2753\n",
      " - Confusion Matrix:\n",
      "[[19122  8271]\n",
      " [ 1058  1772]]\n",
      "\n",
      "üî∏ Random Forest:\n",
      " - AUC-PR: 0.6161\n",
      " - F1 Score: 0.5785\n",
      " - Confusion Matrix:\n",
      "[[26481   912]\n",
      " [ 1307  1523]]\n",
      "\n",
      "üìä Results for Credit_Card Dataset\n",
      "----------------------------------------\n",
      "üîπ Logistic Regression:\n",
      " - AUC-PR: 0.7150\n",
      " - F1 Score: 0.1002\n",
      " - Confusion Matrix:\n",
      "[[55172  1479]\n",
      " [   12    83]]\n",
      "\n",
      "üî∏ Random Forest:\n",
      " - AUC-PR: 0.8142\n",
      " - F1 Score: 0.8276\n",
      " - Confusion Matrix:\n",
      "[[56644     7]\n",
      " [   23    72]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate and capture models\n",
    "lr_fraud, rf_fraud = evaluate_models(X_train_fraud, y_train_fraud, X_test_fraud, y_test_fraud, \"Fraud_Data\")\n",
    "lr_credit, rf_credit = evaluate_models(X_train_credit, y_train_credit, X_test_credit, y_test_credit, \"Credit_Card\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c422979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/rf_credit_model.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now save the Models \n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Save the trained Random Forest models\n",
    "joblib.dump(rf_fraud, \"models/rf_fraud_model.pkl\")\n",
    "joblib.dump(rf_credit, \"models/rf_credit_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e54b63",
   "metadata": {},
   "source": [
    "#### ‚úÖ Step 4: Interpret and Justify Best Model\n",
    "\n",
    "After evaluating both Logistic Regression and Random Forest on the two datasets, we summarize the results and justify the preferred model based on key metrics: AUC-PR, F1 Score, and the Confusion Matrix ‚Äî all crucial for imbalanced classification tasks such as fraud detection.\n",
    "üìä Fraud_Data Dataset\n",
    "Model\tAUC-PR\tF1 Score\tTrue Positives (TP)\tFalse Positives (FP)\tFalse Negatives (FN)\tTrue Negatives (TN)\n",
    "Logistic Regression\t0.2554\t0.2753\t1772\t8271\t1058\t19122\n",
    "Random Forest\t0.6161\t0.5785\t1523\t912\t1307\t26481\n",
    "\n",
    "üìù Interpretation:\n",
    "\n",
    "    Random Forest achieved a much higher AUC-PR and F1 Score, indicating better balance between precision and recall.\n",
    "\n",
    "    It drastically reduced false positives and increased correct non-fraud classification (true negatives).\n",
    "\n",
    "    Slightly higher false negatives are outweighed by major overall gains in performance.\n",
    "\n",
    "‚úÖ Best Model: Random Forest (due to stronger fraud detection performance)\n",
    "üìä Credit_Card Dataset\n",
    "Model\tAUC-PR\tF1 Score\tTrue Positives (TP)\tFalse Positives (FP)\tFalse Negatives (FN)\tTrue Negatives (TN)\n",
    "Logistic Regression\t0.7150\t0.1002\t83\t1479\t12\t55172\n",
    "Random Forest\t‚Äî\t0.8276\t72\t7\t23\t56644\n",
    "\n",
    "üìù Interpretation:\n",
    "\n",
    "    Logistic Regression had a decent AUC-PR, but a very low F1 Score, indicating poor performance on identifying frauds.\n",
    "\n",
    "    Random Forest achieved an excellent F1 Score (0.8276) with extremely low misclassification (only 7 FP and 23 FN).\n",
    "\n",
    "    This indicates strong generalization and practical usability in high-risk domains.\n",
    "\n",
    "‚úÖ Best Model: Random Forest (clear dominance in classification effectiveness)\n",
    "üèÅ Final Recommendation\n",
    "\n",
    "Across both datasets:\n",
    "\n",
    "    ‚úÖ Random Forest consistently delivers superior performance in detecting fraud.\n",
    "\n",
    "    ‚öñÔ∏è Logistic Regression offers interpretability, but fails to meet performance needs for imbalanced fraud detection tasks.\n",
    "\n",
    "    üîê Recommended Model for Deployment:\n",
    "    Random Forest Classifier, due to its strong precision-recall balance, low error rates, and robust generalization across both datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
